{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Download repository and dependencies for the abductive commonsense reasoning tasks."
      ],
      "metadata": {
        "id": "gS2fCDlsgevL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiW8Ebiyf773",
        "outputId": "55cc219d-1617-4c14-9c72-a7a1e9bdaf6f",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'abductive-commonsense-reasoning'...\n",
            "remote: Enumerating objects: 261, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 261 (delta 3), reused 0 (delta 0), pack-reused 216 (from 1)\u001b[K\n",
            "Receiving objects: 100% (261/261), 6.11 MiB | 35.17 MiB/s, done.\n",
            "Resolving deltas: 100% (142/142), done.\n",
            "/content/abductive-commonsense-reasoning/abductive-commonsense-reasoning\n",
            "Obtaining pytorch-transformers from git+https://github.com/csbhagav/pytorch-transformers@generative-finetuning#egg=pytorch-transformers (from -r requirements.txt (line 20))\n",
            "  Cloning https://github.com/csbhagav/pytorch-transformers (to revision generative-finetuning) to ./src/pytorch-transformers\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/csbhagav/pytorch-transformers /content/abductive-commonsense-reasoning/abductive-commonsense-reasoning/src/pytorch-transformers\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-8 (target):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/oyama/oyama.py\", line 33, in target\n",
            "    raise Exception(f\"Command exited with error code {rc}\")\n",
            "Exception: Command exited with error code -2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: Couldn't find '/root/.ollama/id_ed25519'. Generating new private key.\n",
            "Your new public key is: \n",
            "\n",
            "ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOsl+mE/BjcKhfdfnHspnc9v7+2F4SSNvm41Nlg1q+pB\n",
            "\n",
            "2025/03/18 03:34:23 routes.go:1230: INFO server config env=\"map[CUDA_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:2048 OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/root/.ollama/models OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:0 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]\"\n",
            "time=2025-03-18T03:34:23.516Z level=INFO source=images.go:432 msg=\"total blobs: 0\"\n",
            "time=2025-03-18T03:34:23.516Z level=INFO source=images.go:439 msg=\"total unused blobs removed: 0\"\n",
            "time=2025-03-18T03:34:23.516Z level=INFO source=routes.go:1297 msg=\"Listening on 127.0.0.1:11434 (version 0.6.1)\"\n",
            "time=2025-03-18T03:34:23.516Z level=INFO source=gpu.go:217 msg=\"looking for compatible GPUs\"\n",
            "time=2025-03-18T03:34:23.782Z level=INFO source=types.go:130 msg=\"inference compute\" id=GPU-689a41eb-7a9a-c0c0-2c21-ec2b5c7552fc library=cuda variant=v12 compute=7.5 driver=12.4 name=\"Tesla T4\" total=\"14.7 GiB\" available=\"14.6 GiB\"\n",
            "[GIN] 2025/03/18 - 03:34:24 | 200 |      96.119µs |       127.0.0.1 | GET      \"/\"\n",
            "[GIN] 2025/03/18 - 03:34:24 | 200 |       31.56µs |       127.0.0.1 | HEAD     \"/\"\n",
            "time=2025-03-18T03:34:25.205Z level=INFO source=download.go:176 msg=\"downloading 6340dc3229b0 in 16 307 MB part(s)\"\n",
            "time=2025-03-18T03:34:51.497Z level=INFO source=download.go:176 msg=\"downloading 369ca498f347 in 1 387 B part(s)\"\n",
            "time=2025-03-18T03:34:52.812Z level=INFO source=download.go:176 msg=\"downloading 6e4c38e1172f in 1 1.1 KB part(s)\"\n",
            "time=2025-03-18T03:34:54.113Z level=INFO source=download.go:176 msg=\"downloading f4d24e9138dd in 1 148 B part(s)\"\n",
            "time=2025-03-18T03:34:55.438Z level=INFO source=download.go:176 msg=\"downloading 0cb05c6e4e02 in 1 487 B part(s)\"\n",
            "[GIN] 2025/03/18 - 03:35:20 | 200 | 56.422943642s |       127.0.0.1 | POST     \"/api/pull\"\n",
            "Couldn't find '/root/.ollama/id_ed25519'. Generating new private key.\n",
            "Your new public key is: \n",
            "\n",
            "ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOsl+mE/BjcKhfdfnHspnc9v7+2F4SSNvm41Nlg1q+pB\n",
            "\n",
            "2025/03/18 03:34:23 routes.go:1230: INFO server config env=\"map[CUDA_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:2048 OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/root/.ollama/models OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:0 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]\"\n",
            "time=2025-03-18T03:34:23.516Z level=INFO source=images.go:432 msg=\"total blobs: 0\"\n",
            "time=2025-03-18T03:34:23.516Z level=INFO source=images.go:439 msg=\"total unused blobs removed: 0\"\n",
            "time=2025-03-18T03:34:23.516Z level=INFO source=routes.go:1297 msg=\"Listening on 127.0.0.1:11434 (version 0.6.1)\"\n",
            "time=2025-03-18T03:34:23.516Z level=INFO source=gpu.go:217 msg=\"looking for compatible GPUs\"\n",
            "time=2025-03-18T03:34:23.782Z level=INFO source=types.go:130 msg=\"inference compute\" id=GPU-689a41eb-7a9a-c0c0-2c21-ec2b5c7552fc library=cuda variant=v12 compute=7.5 driver=12.4 name=\"Tesla T4\" total=\"14.7 GiB\" available=\"14.6 GiB\"\n",
            "[GIN] 2025/03/18 - 03:34:24 | 200 |      96.119µs |       127.0.0.1 | GET      \"/\"\n",
            "[GIN] 2025/03/18 - 03:34:24 | 200 |       31.56µs |       127.0.0.1 | HEAD     \"/\"\n",
            "time=2025-03-18T03:34:25.205Z level=INFO source=download.go:176 msg=\"downloading 6340dc3229b0 in 16 307 MB part(s)\"\n",
            "time=2025-03-18T03:34:51.497Z level=INFO source=download.go:176 msg=\"downloading 369ca498f347 in 1 387 B part(s)\"\n",
            "time=2025-03-18T03:34:52.812Z level=INFO source=download.go:176 msg=\"downloading 6e4c38e1172f in 1 1.1 KB part(s)\"\n",
            "time=2025-03-18T03:34:54.113Z level=INFO source=download.go:176 msg=\"downloading f4d24e9138dd in 1 148 B part(s)\"\n",
            "time=2025-03-18T03:34:55.438Z level=INFO source=download.go:176 msg=\"downloading 0cb05c6e4e02 in 1 487 B part(s)\"\n",
            "[GIN] 2025/03/18 - 03:35:20 | 200 | 56.422943642s |       127.0.0.1 | POST     \"/api/pull\"\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m--2025-03-18 03:36:42--  https://storage.googleapis.com/ai2-mosaic/public/abductive-commonsense-reasoning-iclr2020/anli.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.69.207, 173.194.79.207, 108.177.96.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.69.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5415361 (5.2M) [application/zip]\n",
            "Saving to: ‘data/anli.zip’\n",
            "\n",
            "anli.zip            100%[===================>]   5.16M  6.86MB/s    in 0.8s    \n",
            "\n",
            "2025-03-18 03:36:43 (6.86 MB/s) - ‘data/anli.zip’ saved [5415361/5415361]\n",
            "\n",
            "--2025-03-18 03:36:43--  https://storage.googleapis.com/ai2-mosaic/public/abductive-commonsense-reasoning-iclr2020/anlg.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.69.207, 173.194.79.207, 108.177.96.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.69.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31541803 (30M) [application/zip]\n",
            "Saving to: ‘data/anlg.zip’\n",
            "\n",
            "anlg.zip            100%[===================>]  30.08M  21.7MB/s    in 1.4s    \n",
            "\n",
            "2025-03-18 03:36:44 (21.7 MB/s) - ‘data/anlg.zip’ saved [31541803/31541803]\n",
            "\n",
            "Archive:  data/anli.zip\n",
            "  inflating: data/anli/train.jsonl   \n",
            "  inflating: data/anli/test.jsonl    \n",
            "  inflating: data/anli/train-labels.lst  \n",
            "  inflating: data/anli/test-labels.lst  \n",
            "  inflating: data/anli/dev-labels.lst  \n",
            "  inflating: data/anli/dev.jsonl     \n",
            "Archive:  data/anlg.zip\n",
            "  inflating: data/anlg/dev-w-comet-preds.jsonl  \n",
            "  inflating: data/anlg/test-w-comet-preds.jsonl  \n",
            "  inflating: data/anlg/train-w-comet-preds.jsonl  \n",
            "--2025-03-18 03:36:47--  https://storage.googleapis.com/ai2-mosaic/public/comet/atomic_pretrained_model.th\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.69.207, 173.194.79.207, 108.177.96.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.69.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1395562813 (1.3G) [application/octet-stream]\n",
            "Saving to: ‘comet-model/atomic_pretrained_model.th’\n",
            "\n",
            "atomic_pretrained_m 100%[===================>]   1.30G  37.3MB/s    in 34s     \n",
            "\n",
            "2025-03-18 03:37:21 (39.4 MB/s) - ‘comet-model/atomic_pretrained_model.th’ saved [1395562813/1395562813]\n",
            "\n",
            "--2025-03-18 03:37:21--  https://storage.googleapis.com/ai2-mosaic/public/comet/vocabulary/encoder_bpe_40000.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.31.207, 142.251.18.207, 142.250.153.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.31.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 815973 (797K) [application/json]\n",
            "Saving to: ‘comet-vocab/encoder_bpe_40000.json’\n",
            "\n",
            "encoder_bpe_40000.j 100%[===================>] 796.85K  1.55MB/s    in 0.5s    \n",
            "\n",
            "2025-03-18 03:37:21 (1.55 MB/s) - ‘comet-vocab/encoder_bpe_40000.json’ saved [815973/815973]\n",
            "\n",
            "--2025-03-18 03:37:21--  https://storage.googleapis.com/ai2-mosaic/public/comet/vocabulary/vocab_40000.bpe\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.31.207, 142.251.18.207, 142.250.153.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.31.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 458495 (448K) [application/octet-stream]\n",
            "Saving to: ‘comet-vocab/vocab_40000.bpe’\n",
            "\n",
            "vocab_40000.bpe     100%[===================>] 447.75K  1.05MB/s    in 0.4s    \n",
            "\n",
            "2025-03-18 03:37:22 (1.05 MB/s) - ‘comet-vocab/vocab_40000.bpe’ saved [458495/458495]\n",
            "\n",
            "--2025-03-18 03:37:22--  https://storage.googleapis.com/ai2-mosaic/public/abductive-commonsense-reasoning-iclr2020/models.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.31.207, 142.251.18.207, 142.250.153.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.31.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10689585763 (10.0G) [application/zip]\n",
            "Saving to: ‘./models.zip’\n",
            "\n",
            "models.zip          100%[===================>]   9.96G  39.8MB/s    in 4m 11s  \n",
            "\n",
            "2025-03-18 03:41:33 (40.6 MB/s) - ‘./models.zip’ saved [10689585763/10689585763]\n",
            "\n",
            "Archive:  models.zip\n",
            "   creating: ./models/\n",
            "   creating: ./models/anlg/\n",
            "   creating: ./models/anli/\n",
            "  inflating: ./models/.DS_Store      \n",
            "  inflating: ./__MACOSX/models/._.DS_Store  \n",
            "   creating: ./models/anlg/lm_all_comet_emb_prefix/\n",
            "   creating: ./models/anlg/restricted_comet_phrases_prefix/\n",
            "   creating: ./models/anlg/all_comet_phrases_prefix/\n",
            "   creating: ./models/anlg/lm_restricted_comet_emb_prefix/\n",
            "   creating: ./models/anlg/only_o1_o2/\n",
            "  inflating: ./models/anli/.DS_Store  \n",
            "  inflating: ./__MACOSX/models/anli/._.DS_Store  \n",
            "   creating: ./models/anli/bert-ft-lr1e-5-batch8-epoch4/\n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/metrics.json  \n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/added_tokens.json  \n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/special_tokens_map.json  \n",
            "   creating: ./models/anlg/lm_all_comet_emb_prefix/checkpoint-30000/\n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/config.json  \n",
            "   creating: ./models/anlg/lm_all_comet_emb_prefix/checkpoint-20000/\n",
            "   creating: ./models/anlg/lm_all_comet_emb_prefix/checkpoint-10000/\n",
            "   creating: ./models/anlg/lm_all_comet_emb_prefix/checkpoint-50000/\n",
            "   creating: ./models/anlg/lm_all_comet_emb_prefix/checkpoint-40000/\n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/merges.txt  \n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/training_args.bin  \n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/pytorch_model.bin  \n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/vocab.json  \n",
            "  inflating: ./models/anlg/restricted_comet_phrases_prefix/metrics.json  \n",
            "  inflating: ./models/anlg/restricted_comet_phrases_prefix/added_tokens.json  \n",
            "  inflating: ./models/anlg/restricted_comet_phrases_prefix/special_tokens_map.json  \n",
            "  inflating: ./models/anlg/restricted_comet_phrases_prefix/config.json  \n",
            "  inflating: ./models/anlg/restricted_comet_phrases_prefix/merges.txt  \n",
            "  inflating: ./models/anlg/restricted_comet_phrases_prefix/training_args.bin  \n",
            "  inflating: ./models/anlg/restricted_comet_phrases_prefix/pytorch_model.bin  \n",
            "  inflating: ./models/anlg/restricted_comet_phrases_prefix/vocab.json  \n",
            "  inflating: ./models/anlg/all_comet_phrases_prefix/metrics.json  \n",
            "  inflating: ./models/anlg/all_comet_phrases_prefix/added_tokens.json  \n",
            "  inflating: ./models/anlg/all_comet_phrases_prefix/special_tokens_map.json  \n",
            "  inflating: ./models/anlg/all_comet_phrases_prefix/config.json  \n",
            "  inflating: ./models/anlg/all_comet_phrases_prefix/merges.txt  \n",
            "  inflating: ./models/anlg/all_comet_phrases_prefix/training_args.bin  \n",
            "  inflating: ./models/anlg/all_comet_phrases_prefix/pytorch_model.bin  \n",
            "  inflating: ./models/anlg/all_comet_phrases_prefix/vocab.json  \n",
            "  inflating: ./models/anlg/lm_restricted_comet_emb_prefix/metrics.json  \n",
            "  inflating: ./models/anlg/lm_restricted_comet_emb_prefix/added_tokens.json  \n",
            "  inflating: ./models/anlg/lm_restricted_comet_emb_prefix/special_tokens_map.json  \n",
            "  inflating: ./models/anlg/lm_restricted_comet_emb_prefix/config.json  \n",
            "   creating: ./models/anlg/lm_restricted_comet_emb_prefix/checkpoint-20000/\n",
            "   creating: ./models/anlg/lm_restricted_comet_emb_prefix/checkpoint-10000/\n",
            "  inflating: ./models/anlg/lm_restricted_comet_emb_prefix/merges.txt  \n",
            "  inflating: ./models/anlg/lm_restricted_comet_emb_prefix/training_args.bin  \n",
            "  inflating: ./models/anlg/lm_restricted_comet_emb_prefix/pytorch_model.bin  \n",
            "  inflating: ./models/anlg/lm_restricted_comet_emb_prefix/vocab.json  \n",
            "  inflating: ./models/anlg/only_o1_o2/metrics.json  \n",
            "  inflating: ./models/anlg/only_o1_o2/added_tokens.json  \n",
            "  inflating: ./models/anlg/only_o1_o2/special_tokens_map.json  \n",
            "  inflating: ./models/anlg/only_o1_o2/config.json  \n",
            "  inflating: ./models/anlg/only_o1_o2/merges.txt  \n",
            "  inflating: ./models/anlg/only_o1_o2/training_args.bin  \n",
            "  inflating: ./models/anlg/only_o1_o2/pytorch_model.bin  \n",
            "  inflating: ./models/anlg/only_o1_o2/vocab.json  \n",
            "  inflating: ./models/anli/bert-ft-lr1e-5-batch8-epoch4/metrics.json  \n",
            "  inflating: ./models/anli/bert-ft-lr1e-5-batch8-epoch4/.DS_Store  \n",
            "  inflating: ./__MACOSX/models/anli/bert-ft-lr1e-5-batch8-epoch4/._.DS_Store  \n",
            "  inflating: ./models/anli/bert-ft-lr1e-5-batch8-epoch4/dev_output_predictions.jsonl  \n",
            "  inflating: ./models/anli/bert-ft-lr1e-5-batch8-epoch4/pytorch_model.bin  \n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/checkpoint-30000/config.json  \n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/checkpoint-30000/training_args.bin  \n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/checkpoint-30000/pytorch_model.bin  \n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/checkpoint-20000/config.json  \n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/checkpoint-20000/training_args.bin  \n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/checkpoint-20000/pytorch_model.bin  \n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/checkpoint-10000/config.json  \n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/checkpoint-10000/training_args.bin  \n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/checkpoint-10000/pytorch_model.bin  \n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/checkpoint-50000/config.json  \n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/checkpoint-50000/training_args.bin  \n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/checkpoint-50000/pytorch_model.bin  \n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/checkpoint-40000/config.json  \n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/checkpoint-40000/training_args.bin  \n",
            "  inflating: ./models/anlg/lm_all_comet_emb_prefix/checkpoint-40000/pytorch_model.bin  \n",
            "  inflating: ./models/anlg/lm_restricted_comet_emb_prefix/checkpoint-20000/config.json  \n",
            "  inflating: ./models/anlg/lm_restricted_comet_emb_prefix/checkpoint-20000/training_args.bin  \n",
            "  inflating: ./models/anlg/lm_restricted_comet_emb_prefix/checkpoint-20000/pytorch_model.bin  \n",
            "  inflating: ./models/anlg/lm_restricted_comet_emb_prefix/checkpoint-10000/config.json  \n",
            "  inflating: ./models/anlg/lm_restricted_comet_emb_prefix/checkpoint-10000/training_args.bin  \n",
            "  inflating: ./models/anlg/lm_restricted_comet_emb_prefix/checkpoint-10000/pytorch_model.bin  \n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/allenai/abductive-commonsense-reasoning.git\n",
        "%cd abductive-commonsense-reasoning\n",
        "!pip install -r requirements.txt\n",
        "!sh get-data.sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -q git+https://github.com/HawkClaws/oyama.git ollama\n",
        "from oyama import oyama\n",
        "import ollama\n",
        "\n",
        "model_path = \"deepseek-r1:8b\"\n",
        "model_name = oyama.run(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KWYnVzGQhfxN",
        "outputId": "e52163d4-4c58-459b-c2d7-a26ea24f7576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "command:=ollama --version\n",
            "Output: Warning: could not connect to a running Ollama instance\n",
            "Warning: client version is 0.6.1\n",
            "Warning: could not connect to a running Ollama instance\n",
            "Warning: client version is 0.6.1\n",
            "command:=ollama serve\n",
            "Server is not ready yet. Retrying...\n",
            "Server is ready.\n",
            "command:=ollama pull deepseek-r1:8b\n",
            "Output: \u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
            "pulling 6340dc3229b0... 100% ▕████████████████▏ 4.9 GB                         \u001b[K\n",
            "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \u001b[K\n",
            "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \u001b[K\n",
            "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \u001b[K\n",
            "pulling 0cb05c6e4e02... 100% ▕████████████████▏  487 B                         \u001b[K\n",
            "verifying sha256 digest \u001b[K\n",
            "writing manifest \u001b[K\n",
            "success \u001b[K\u001b[?25h\u001b[?2026l\n",
            "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
            "pulling 6340dc3229b0... 100% ▕████████████████▏ 4.9 GB                         \u001b[K\n",
            "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \u001b[K\n",
            "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \u001b[K\n",
            "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \u001b[K\n",
            "pulling 0cb05c6e4e02... 100% ▕████████████████▏  487 B                         \u001b[K\n",
            "verifying sha256 digest \u001b[K\n",
            "writing manifest \u001b[K\n",
            "success \u001b[K\u001b[?25h\u001b[?2026l\n",
            "Enable Model:deepseek-r1:8b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Load dev set\n",
        "df_dev = pd.read_json(\"/content/abductive-commonsense-reasoning/abductive-commonsense-reasoning/data/anli/dev.jsonl\", lines=True)  # each line is one JSON record\n",
        "labels_dev = pd.read_csv(\"/content/abductive-commonsense-reasoning/abductive-commonsense-reasoning/data/anli/dev-labels.lst\", header=None, names=[\"label\"])\n",
        "df_dev[\"label\"] = labels_dev[\"label\"]\n",
        "\n",
        "# 2. Load test set\n",
        "df_test = pd.read_json(\"/content/abductive-commonsense-reasoning/abductive-commonsense-reasoning/data/anli/test.jsonl\", lines=True)\n",
        "labels_test = pd.read_csv(\"/content/abductive-commonsense-reasoning/abductive-commonsense-reasoning/data/anli/test-labels.lst\", header=None, names=[\"label\"])\n",
        "df_test[\"label\"] = labels_test[\"label\"]\n",
        "\n",
        "\n",
        "\n",
        "def make_prompt(row):\n",
        "    return (\n",
        "        f\"Given the following two observations, predict what occurred inbetween the observations:\\n\"\n",
        "        f\"obs 1. {row['obs1']}\\n\"\n",
        "        f\"obs 2. {row['obs2']}\\n\\n\"\n",
        "        f\"Which hypothesis is most likely to have occurred between the observations?\\n\"\n",
        "        f\"hyp 1. {row['hyp1']}\\n\"\n",
        "        f\"hyp 2. {row['hyp2']}\\n\\n\"\n",
        "        \"Please respond with ONLY the integer of the hypothesis (1 or 2).\"\n",
        "        \"No explanation, no other text.\"\n",
        "    )\n",
        "\n",
        "df_test[\"prompt\"] = df_test.apply(make_prompt, axis=1)\n",
        "print(df_test[\"prompt\"][0])\n"
      ],
      "metadata": {
        "id": "eYpxI8C9iVNx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e672353-cefb-4b4c-f632-48a60bd08dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given the following two observations, predict what occurred inbetween the observations:\n",
            "obs 1. Jane was a professor teaching piano to students.\n",
            "obs 2. Jane spent the morning sipping coffee and reading a book.\n",
            "\n",
            "Which hypothesis is most likely to have occurred between the observations?\n",
            "hyp 1. Two of Jane's students were early for their lessons.\n",
            "hyp 2. None of Jane's students had a lesson that day.\n",
            "\n",
            "Please respond with ONLY the integer of the hypothesis (1 or 2).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ollama\n",
        "import pandas as pd\n",
        "import concurrent.futures\n",
        "import re\n",
        "\n",
        "model_name = \"deepseek-r1:8b\"\n",
        "\n",
        "def parse_digit(raw_text):\n",
        "    matches = re.findall(r'\\b([12])\\b', raw_text)\n",
        "    if not matches:\n",
        "        return None\n",
        "    return matches[-1]  # get the last occurrence\n",
        "\n",
        "def query_model(prompt_text):\n",
        "    response = ollama.chat(\n",
        "        model=model_name,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt_text}],\n",
        "        stream=False\n",
        "    )\n",
        "    full_text = response.get(\"message\", {}).get(\"content\", \"\")\n",
        "    extracted_digit = parse_digit(full_text)\n",
        "    return extracted_digit, full_text\n",
        "\n",
        "def run_inference_parallel(df, max_workers=4):\n",
        "    df[\"prediction\"] = None\n",
        "    df[\"raw_response\"] = None\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        futures = {}\n",
        "        for idx, row in df.iterrows():\n",
        "            prompt_text = row[\"prompt\"]\n",
        "            futures[executor.submit(query_model, prompt_text)] = idx\n",
        "\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            idx = futures[future]\n",
        "            try:\n",
        "                digit, raw = future.result()\n",
        "                df.at[idx, \"prediction\"] = digit\n",
        "                df.at[idx, \"raw_response\"] = raw\n",
        "            except Exception as e:\n",
        "                print(f\"Error on row {idx}: {e}\")\n",
        "                df.at[idx, \"prediction\"] = None\n",
        "                df.at[idx, \"raw_response\"] = \"\"\n",
        "    return df\n",
        "\n",
        "df_test_small = df_test.sample(n=500).copy()\n",
        "anli_test_small_results = run_inference_parallel(df_test_small, max_workers=8)"
      ],
      "metadata": {
        "id": "Z1iDXU3oge66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anli_test_small_results.to_csv(\"/content/sample_data/anli_test_small_results.csv\", index=False)"
      ],
      "metadata": {
        "id": "DXWNr6escEMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anli_test_small_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bUZKb-Xp5ILj",
        "outputId": "fbcbc3f8-fc52-4430-92c0-603eca837bdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    story_id  \\\n",
              "1587  31dd9751-0538-404f-901d-48ce7e8fa86b-1   \n",
              "695   29157c96-61c7-46d8-9ff2-12978b0b5e43-1   \n",
              "1392  aad0f120-f41a-4f05-9b62-955226ce3300-1   \n",
              "1998   66c79a45-25be-4066-9d36-016637bd57c52   \n",
              "2841  5b0a5d33-ad13-426b-9758-17387eeff03c-1   \n",
              "...                                      ...   \n",
              "2202  4a6a63bc-4a93-4e24-ae11-5e06a667e845-1   \n",
              "1195  99cedf3e-db5f-41ea-96b0-de35c2cfad0b-1   \n",
              "2565  c27472b1-6609-43b4-80ae-b56cb4b1995f-1   \n",
              "1892  4b471cd7-304b-400c-a06a-c4fa0ec9de93-1   \n",
              "2879  36fcc4fa-beaf-42ff-b541-9b6b76046382-1   \n",
              "\n",
              "                                                   obs1  \\\n",
              "1587    Kevin and Glenn's mother really loved musicals.   \n",
              "695                            Bob loved to rock climb.   \n",
              "1392                              Pete was a quiet man.   \n",
              "1998               Kev's dad asked to take him hunting.   \n",
              "2841                               Anna could not swim.   \n",
              "...                                                 ...   \n",
              "2202                I got a bike for my sixth birthday.   \n",
              "1195         Late at night, May snuck out of her house.   \n",
              "2565  Rosie comes home late from a party and goes st...   \n",
              "1892               Able was given a calf by his father.   \n",
              "2879                 Chris was a happy 13 year old boy.   \n",
              "\n",
              "                                                   obs2  \\\n",
              "1587  For her 50th birthday the boys surprised her w...   \n",
              "695                               He fell to his death.   \n",
              "1392  Pete shot the man in defense, and left him und...   \n",
              "1998                   Kev decided not to come hunting.   \n",
              "2841        Soon she was swimming quickly and expertly!   \n",
              "...                                                 ...   \n",
              "2202  That gave me enough momentum to balance and pe...   \n",
              "1195           Her town was beautiful in the moonlight!   \n",
              "2565  She learns her lesson and vows never to neglec...   \n",
              "1892  Both Able and the calf had grown up but his fa...   \n",
              "2879  He liked his surprise gift of inline skates th...   \n",
              "\n",
              "                                                   hyp1  \\\n",
              "1587     Kevin and Glenn's mother was about to turn 45.   \n",
              "695       One day, on a climb, Bob safety made the top.   \n",
              "1392  Pete made a friend with a stranger who trespas...   \n",
              "1998                  Kev hates animals and loves guns.   \n",
              "2841                     Anna took lessons at the pool.   \n",
              "...                                                 ...   \n",
              "2202                      I got a flat tire on my bike.   \n",
              "1195         She walked around and explored the forest.   \n",
              "2565  Rosie left her contacts in her eyes and got an...   \n",
              "1892  Able said he would return when the calf was gr...   \n",
              "2879     Chris received lots of gifts for his birthday.   \n",
              "\n",
              "                                                   hyp2  label  \\\n",
              "1587          they wanted to find her the best present.      2   \n",
              "695                Bob slipped and fell while climbing.      2   \n",
              "1392                    A stranger tried to shoot Pete.      2   \n",
              "1998                  Kev loves animals and hates guns.      2   \n",
              "2841                     Anna was afraid of the water,.      1   \n",
              "...                                                 ...    ...   \n",
              "2202                       My dad pushed me and let go.      2   \n",
              "1195                           May walked on the roads.      2   \n",
              "2565     Rosie didn't get enough food before the party.      1   \n",
              "1892                           Abby's father than left.      2   \n",
              "2879  None of his friends came to his surprise birth...      1   \n",
              "\n",
              "                                                 prompt prediction  \\\n",
              "1587  Given the following two observations, predict ...          2   \n",
              "695   Given the following two observations, predict ...          2   \n",
              "1392  Given the following two observations, predict ...          2   \n",
              "1998  Given the following two observations, predict ...          1   \n",
              "2841  Given the following two observations, predict ...          1   \n",
              "...                                                 ...        ...   \n",
              "2202  Given the following two observations, predict ...          2   \n",
              "1195  Given the following two observations, predict ...          1   \n",
              "2565  Given the following two observations, predict ...          1   \n",
              "1892  Given the following two observations, predict ...          2   \n",
              "2879  Given the following two observations, predict ...          1   \n",
              "\n",
              "                                           raw_response  \n",
              "1587  <think>\\nOkay, so I need to figure out which h...  \n",
              "695   <think>\\nAlright, so I'm trying to figure out ...  \n",
              "1392  <think>\\nOkay, so I need to figure out which h...  \n",
              "1998  <think>\\nOkay, so I need to figure out what ha...  \n",
              "2841  <think>\\nOkay, so I need to figure out which h...  \n",
              "...                                                 ...  \n",
              "2202  <think>\\nOkay, so I've got this problem here w...  \n",
              "1195  <think>\\nOkay, so I've got this problem here w...  \n",
              "2565  <think>\\nOkay, so I'm trying to figure out wha...  \n",
              "1892  <think>\\nOkay, so I'm trying to figure out wha...  \n",
              "2879  <think>\\nOkay, so I've got this question here ...  \n",
              "\n",
              "[500 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-389509a0-35c9-48c5-b2a0-83a823db3c87\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>story_id</th>\n",
              "      <th>obs1</th>\n",
              "      <th>obs2</th>\n",
              "      <th>hyp1</th>\n",
              "      <th>hyp2</th>\n",
              "      <th>label</th>\n",
              "      <th>prompt</th>\n",
              "      <th>prediction</th>\n",
              "      <th>raw_response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1587</th>\n",
              "      <td>31dd9751-0538-404f-901d-48ce7e8fa86b-1</td>\n",
              "      <td>Kevin and Glenn's mother really loved musicals.</td>\n",
              "      <td>For her 50th birthday the boys surprised her w...</td>\n",
              "      <td>Kevin and Glenn's mother was about to turn 45.</td>\n",
              "      <td>they wanted to find her the best present.</td>\n",
              "      <td>2</td>\n",
              "      <td>Given the following two observations, predict ...</td>\n",
              "      <td>2</td>\n",
              "      <td>&lt;think&gt;\\nOkay, so I need to figure out which h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>29157c96-61c7-46d8-9ff2-12978b0b5e43-1</td>\n",
              "      <td>Bob loved to rock climb.</td>\n",
              "      <td>He fell to his death.</td>\n",
              "      <td>One day, on a climb, Bob safety made the top.</td>\n",
              "      <td>Bob slipped and fell while climbing.</td>\n",
              "      <td>2</td>\n",
              "      <td>Given the following two observations, predict ...</td>\n",
              "      <td>2</td>\n",
              "      <td>&lt;think&gt;\\nAlright, so I'm trying to figure out ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1392</th>\n",
              "      <td>aad0f120-f41a-4f05-9b62-955226ce3300-1</td>\n",
              "      <td>Pete was a quiet man.</td>\n",
              "      <td>Pete shot the man in defense, and left him und...</td>\n",
              "      <td>Pete made a friend with a stranger who trespas...</td>\n",
              "      <td>A stranger tried to shoot Pete.</td>\n",
              "      <td>2</td>\n",
              "      <td>Given the following two observations, predict ...</td>\n",
              "      <td>2</td>\n",
              "      <td>&lt;think&gt;\\nOkay, so I need to figure out which h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>66c79a45-25be-4066-9d36-016637bd57c52</td>\n",
              "      <td>Kev's dad asked to take him hunting.</td>\n",
              "      <td>Kev decided not to come hunting.</td>\n",
              "      <td>Kev hates animals and loves guns.</td>\n",
              "      <td>Kev loves animals and hates guns.</td>\n",
              "      <td>2</td>\n",
              "      <td>Given the following two observations, predict ...</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;think&gt;\\nOkay, so I need to figure out what ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2841</th>\n",
              "      <td>5b0a5d33-ad13-426b-9758-17387eeff03c-1</td>\n",
              "      <td>Anna could not swim.</td>\n",
              "      <td>Soon she was swimming quickly and expertly!</td>\n",
              "      <td>Anna took lessons at the pool.</td>\n",
              "      <td>Anna was afraid of the water,.</td>\n",
              "      <td>1</td>\n",
              "      <td>Given the following two observations, predict ...</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;think&gt;\\nOkay, so I need to figure out which h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2202</th>\n",
              "      <td>4a6a63bc-4a93-4e24-ae11-5e06a667e845-1</td>\n",
              "      <td>I got a bike for my sixth birthday.</td>\n",
              "      <td>That gave me enough momentum to balance and pe...</td>\n",
              "      <td>I got a flat tire on my bike.</td>\n",
              "      <td>My dad pushed me and let go.</td>\n",
              "      <td>2</td>\n",
              "      <td>Given the following two observations, predict ...</td>\n",
              "      <td>2</td>\n",
              "      <td>&lt;think&gt;\\nOkay, so I've got this problem here w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>99cedf3e-db5f-41ea-96b0-de35c2cfad0b-1</td>\n",
              "      <td>Late at night, May snuck out of her house.</td>\n",
              "      <td>Her town was beautiful in the moonlight!</td>\n",
              "      <td>She walked around and explored the forest.</td>\n",
              "      <td>May walked on the roads.</td>\n",
              "      <td>2</td>\n",
              "      <td>Given the following two observations, predict ...</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;think&gt;\\nOkay, so I've got this problem here w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2565</th>\n",
              "      <td>c27472b1-6609-43b4-80ae-b56cb4b1995f-1</td>\n",
              "      <td>Rosie comes home late from a party and goes st...</td>\n",
              "      <td>She learns her lesson and vows never to neglec...</td>\n",
              "      <td>Rosie left her contacts in her eyes and got an...</td>\n",
              "      <td>Rosie didn't get enough food before the party.</td>\n",
              "      <td>1</td>\n",
              "      <td>Given the following two observations, predict ...</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;think&gt;\\nOkay, so I'm trying to figure out wha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1892</th>\n",
              "      <td>4b471cd7-304b-400c-a06a-c4fa0ec9de93-1</td>\n",
              "      <td>Able was given a calf by his father.</td>\n",
              "      <td>Both Able and the calf had grown up but his fa...</td>\n",
              "      <td>Able said he would return when the calf was gr...</td>\n",
              "      <td>Abby's father than left.</td>\n",
              "      <td>2</td>\n",
              "      <td>Given the following two observations, predict ...</td>\n",
              "      <td>2</td>\n",
              "      <td>&lt;think&gt;\\nOkay, so I'm trying to figure out wha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2879</th>\n",
              "      <td>36fcc4fa-beaf-42ff-b541-9b6b76046382-1</td>\n",
              "      <td>Chris was a happy 13 year old boy.</td>\n",
              "      <td>He liked his surprise gift of inline skates th...</td>\n",
              "      <td>Chris received lots of gifts for his birthday.</td>\n",
              "      <td>None of his friends came to his surprise birth...</td>\n",
              "      <td>1</td>\n",
              "      <td>Given the following two observations, predict ...</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;think&gt;\\nOkay, so I've got this question here ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-389509a0-35c9-48c5-b2a0-83a823db3c87')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-389509a0-35c9-48c5-b2a0-83a823db3c87 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-389509a0-35c9-48c5-b2a0-83a823db3c87');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b478c343-c1ff-4d06-b3e5-8f8a78b587a0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b478c343-c1ff-4d06-b3e5-8f8a78b587a0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b478c343-c1ff-4d06-b3e5-8f8a78b587a0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f812abfe-1921-42be-8598-17f843c5c8ec\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_test_small')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f812abfe-1921-42be-8598-17f843c5c8ec button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_test_small');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test_small",
              "summary": "{\n  \"name\": \"df_test_small\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"story_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"8963d8ee-b8f5-4c88-bda5-94486a572a16-1\",\n          \"2f335e3b-00d0-4fc2-8d6d-b170275ceda9-1\",\n          \"e709be25-6b63-4fcc-a3c6-cfd4b66a5b73-1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"obs1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 498,\n        \"samples\": [\n          \"The family decided to go on a picnic.\",\n          \"Tina started her first violin lesson.\",\n          \"Bill was late on the rent.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"obs2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"Johnny smiled a big, red-toothed grin.\",\n          \"Thankfully it didn't break.\",\n          \"His mom had to settle for scrambled eggs.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hyp1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"Johnny had eaten a red licorice stick.\",\n          \"Tina walked into the lesson having forgotten her violin.\",\n          \"Ed burnt the incomplete thing.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hyp2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"He covered Johnny's tooth with blue toothpaste.\",\n          \"Tina tightened the strings too tight.\",\n          \"Ed ruined the pancakes and only had eggs left.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"Given the following two observations, predict what occurred inbetween the observations:\\nobs 1. A dental hygienist visited Johnny's school.\\nobs 2. Johnny smiled a big, red-toothed grin.\\n\\nWhich hypothesis is most likely to have occurred between the observations?\\nhyp 1. Johnny had eaten a red licorice stick.\\nhyp 2. He covered Johnny's tooth with blue toothpaste.\\n\\nPlease respond with ONLY the integer of the hypothesis (1 or 2).\",\n          \"Given the following two observations, predict what occurred inbetween the observations:\\nobs 1. Tina started her first violin lesson.\\nobs 2. Thankfully it didn't break.\\n\\nWhich hypothesis is most likely to have occurred between the observations?\\nhyp 1. Tina walked into the lesson having forgotten her violin.\\nhyp 2. Tina tightened the strings too tight.\\n\\nPlease respond with ONLY the integer of the hypothesis (1 or 2).\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prediction\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw_response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"<think>\\nOkay, so I've got this question here, and I need to figure out what happened between the two observations. Let me read it again carefully.\\n\\nThe first observation is that a dental hygienist visited Johnny's school. The second observation is that Johnny smiled a big, red-toothed grin. Now, I have to choose between two hypotheses: Hypothesis 1 suggests Johnny ate a red licorice stick, and Hypothesis 2 says he covered his tooth with blue toothpaste.\\n\\nAlright, let me break this down. A dental hygienist visiting the school is probably part of a routine check-up or education program about oral hygiene. So maybe they taught the kids about brushing their teeth, flossing, etc. That's what I know from experience\\u2014dental visits often educate on good habits.\\n\\nNow, Johnny smiling with a big red grin makes me think something is different about his mouth. Red usually means something is stained or perhaps he had something colorful in there. So, why would his smile be red? If he ate a red licorice stick, that could make sense because licorice is naturally red and sticky, so it might get stuck on his teeth. That's a plausible reason for the red tooth.\\n\\nOn the other hand, blue toothpaste. Hmm, I'm not sure about that one. Blue toothpaste is something I've heard of being used in some cases, maybe as a temporary cover or for a specific purpose like desensitizing teeth. But would a dental hygienist do that? It seems less likely because toothpaste usually has fluoride to help prevent cavities, and blue toothpaste isn't standard. Plus, covering a tooth with toothpaste wouldn't necessarily make it red; it might just change the color temporarily, but I'm not sure if that's why his grin is red.\\n\\nSo, putting it together: a dental visit likely involved some education or check-up, which could include a visual inspection of Johnny's teeth. If he had something stuck on his tooth, like a red licorice, that would show up when the hygienist checked his mouth. Therefore, the most logical explanation is that he ate the red licorice, leading to the red-toothed grin.\\n\\nWait, but could there be another reason? Maybe Johnny just has a naturally red-stained tooth for some other reason, like maybe he had braces or something. But the question gives me two options, so I have to pick between these two. Since blue toothpaste doesn't really explain the red color as effectively as the licorice, I think Hypothesis 1 is more likely.\\n</think>\\n\\n1\",\n          \"<think>\\nOkay, so I need to figure out what happened between observation 1 and observation 2 in this scenario. Let me start by breaking down the information given.\\n\\nObservation 1 is that Tina started her first violin lesson. So, she was probably at the beginning of a new experience, maybe a bit nervous or excited. Observation 2 says that thankfully it didn't break. That suggests something happened during the lesson that could have gone wrong, but it didn't.\\n\\nNow, I'm supposed to choose between two hypotheses: Hypothesis 1 is that Tina walked into the lesson having forgotten her violin. Hypothesis 2 is that she tightened the strings too tight.\\n\\nLet me think about each hypothesis. For Hypothesis 1, if Tina forgot her violin, that would mean she didn't bring it to the lesson. Maybe she realized this when she started playing and couldn't do anything, which could have caused some issues, but since it didn't break, maybe she handled it well or perhaps someone helped her borrow a violin. But I'm not sure if forgetting the violin is the most likely scenario because the second observation specifically mentions that it didn't break, implying something happened during play.\\n\\nHypothesis 2 suggests that Tina tightened the strings too much. If she's new to playing the violin, maybe she wasn't experienced in tuning or adjusting the strings properly. Tighter strings can cause issues like breaking or making the instrument difficult to play. So if she tightened them too tight, that could explain why something happened during the lesson that was problematic but didn't actually break.\\n\\nConsidering both points, the fact that it \\\"didn't break\\\" suggests that there was a moment of potential danger, like strings snapping or something going wrong with the violin's setup. Hypothesis 2 directly addresses an action Tina took that could have caused such a situation, whereas Hypothesis 1 is more about forgetting an essential item but doesn't tie as directly to why it didn't break.\\n\\nI think the most likely hypothesis is Hypothesis 2 because it directly relates to an action that could lead to problems during the lesson, which would explain why something almost broke but didn't.\\n</think>\\n\\nThe most likely hypothesis is Hypothesis 2. \\n\\n2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating the accuracy of the deepseek distill model over 500 randomly sampled tests"
      ],
      "metadata": {
        "id": "GN3_DR5SV3RM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "anli_test_small_results['label_str'] = anli_test_small_results['label'].astype(str)\n",
        "anli_test_small_results['prediction_str'] = anli_test_small_results['prediction'].astype(str)\n",
        "\n",
        "correct_mask = anli_test_small_results['label_str'] == anli_test_small_results['prediction_str']\n",
        "num_correct = correct_mask.sum()\n",
        "total = len(anli_test_small_results)\n",
        "accuracy = num_correct / total\n",
        "\n",
        "print(f\"Correct: {num_correct} / {total}\")\n",
        "print(f\"Accuracy: {accuracy:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BUqrYkR5JVb",
        "outputId": "1314c9cf-d592-4aff-8959-32e8a9bf837f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct: 383 / 500\n",
            "Accuracy: 76.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V9ruuYDq7JGp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
